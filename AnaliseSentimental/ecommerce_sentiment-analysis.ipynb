{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#bibliotecas padrao\nimport pandas as pd #csv, dataframes\n\n#preparacao dos dados\nimport re #expressoes regulares\nfrom sklearn.feature_extraction.text import CountVectorizer #vetorizacao via BoW\n\n#modelo\nfrom sklearn.naive_bayes import MultinomialNB #modelo tipo navie bayes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Sumário</h1>"},{"metadata":{},"cell_type":"markdown","source":"* Importando e limpando os dados<br> \n* Preparação dos dados<br>\n * RegEx<br>\n* Criando o modelo<br>\n * Vetorização<br> \n   * BoW<br>\n   * TD - IDF<br>\n* Treinamento<br>\n* Teste<br>\n* Predições<br>\n* Respostas"},{"metadata":{},"cell_type":"markdown","source":"<h1>Importando e limpando os dados</h1>"},{"metadata":{},"cell_type":"markdown","source":"* <p1>Os <a href = \"https://www.kaggle.com/thiagopanini/e-commerce-sentiment-analysis-eda-viz-nlp\">dados</a> referem-se ao e-commerce no território brasileiro entre 09/2016 até 10/2018.</p1><br><br>\n* <p1>O arquivo de interesse chama-se 'olist_order_reviews_dataset.csv' e contém informações sobre os reviews relacionados às ordens de compra no e-commerce no Brasil no mesmo intervalo temporal.</p1><br><br>\n* <p1> Os comentarios dos reviews estão na coluna 'review_comment_message', e as notas estão na coluna 'review_score'.</p1><br><br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#importando os dados de interesse\ndf = pd.read_csv('/kaggle/input/brazilian-ecommerce/olist_order_reviews_dataset.csv', \n                 usecols = ['review_score','review_comment_message'])\n\n#renomeando colunas\ndf.columns = ['score','comentarios']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#removendo dados ausentes do dataframe\ndf.dropna(inplace = True)\n\n#resetando índice\ndf.reset_index(inplace = True, drop = True)\n\n#imprime tuple(#linhas,#colunas)\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Preparação dos dados</h1>"},{"metadata":{},"cell_type":"markdown","source":"<p1>Segundo <a href = \"https://www.kaggle.com/thiagopanini/e-commerce-sentiment-analysis-eda-viz-nlp\"> Panini</a>, para fazer a análise sentimental é necessário preparar os dados e transformá-los em vetores, para que por fim sejam interpretados por um modelo de Machine Learning. A preparação consiste, dentre outros passos, em aplicar Expressões Regulares (RegEx) no conjunto de dados, afim de identificar padrões e extraí-los. A vetorização depende do modelo utilizado, e consiste em representar palavras vetorialmente em função da sua frequência em um documento e/ou de sua importância."},{"metadata":{},"cell_type":"markdown","source":"<h2>RegEx</h2>"},{"metadata":{},"cell_type":"markdown","source":"* É preciso criar uma função que substitua as quebras de linhas encontradas nos textos por espaços em branco\n* É preciso criar uma função que substitua os valores numéricos pela palavra 'numero'\n* É preciso criar uma função que substitua caracteres especiais por espaços em branco"},{"metadata":{"trusted":true},"cell_type":"code","source":"def reQuebraDeLinha(texto_lista):\n    #quebras de linha - \\n\\r2\n    #re.sub -> expressão regular que substitui um padrão por outro\n    \n    texto_lista = [re.sub('\\r\\n',' ', i) for i in texto_lista]   # list comprehension para substituir\n                                                                      # as quebras de linha por espaços em branco\n    return texto_lista","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def numTransform(texto_lista):\n    #[] indica quais caracteres estou considerando\n    #0-9 -> numeros no intervalo (0,9)\n    #'+' -> na documentação diz que significa que o que estiver imediatamente antes dele precisa aparecer 1 ou mais vezes,\n    #       porém não entendi muito bem. Mas sem o + na RegEx a palavra 'numero' se repete\n    \n    texto_lista = [re.sub('[0-9]+', 'numero ', i) for i in texto_lista]\n    return texto_lista","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\ndef negacao(texto_lista):\n    #[] indica quais caracteres estou considerando\n    texto_lista = [re.sub('([nN][ãÃaA][oO]|[ñÑ]| [nN] )', 'negacao', i) for i in texto_lista]\n    return texto_lista\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def charEsp(texto_lista):\n    #\\W caracter nao alfa-numerico (^[a-zA-Z0-9])\n    texto_lista = [re.sub('\\W', ' ', i) for i in texto_lista]\n    return texto_lista","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preparacao(texto_lista):\n    #aplicando a funcao requebraDeLinha()\n    texto_lista = reQuebraDeLinha(texto_lista)\n\n    #aplicando a função numTransform()\n    texto_lista = numTransform(texto_lista)\n\n    #aplicando a função negacao()\n    #texto_lista = negacao(texto_lista)\n    \n    #aplicando a função charEsp()\n    texto_lista = charEsp(texto_lista)\n    \n    return texto_lista","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.comentarios = preparacao(df['comentarios'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0 = negativo e 1 = positivo\nmapa_score = {1: 'negativo', 2: 'negativo', 3: 'negativo', 4: 'positivo', 5: 'positivo'}\ndf['sentimento'] = df['score'].map(mapa_score)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sentimento.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Criando o modelo</h1>"},{"metadata":{},"cell_type":"markdown","source":"<h2>Vetorização</h2>"},{"metadata":{},"cell_type":"markdown","source":"<h3>Bag of Words (BoW)</h3>\n\nSegundo <a href = \"https://www.analyticsvidhya.com/blog/2020/02/quick-introduction-bag-of-words-bow-tf-idf/\">Analytics Vidhya</a>, o modelo BoW é definido como uma forma simples de fazer uma representação vetorial de um dado termo \"t\" presente em um dado documento \"d\", a partir de sua frequência de ocorrência no mesmo. O vetor é gerado de forma tal, que para cada termo presente no texto está associado um valor binário (0 ou 1), onde 0 significa não ocorrência e 1 indica ocorrência do termo em um dado documento."},{"metadata":{},"cell_type":"markdown","source":"<h3>Term Frequency Inverse Document Frequency (TF - IDF)</h3>\n\nO modelo TF-IDF consiste em quantificar a importância de cada palavra no conjunto de dados e representá-las como um vetor, onde cada elemento destes é um número do tipo float que está associado a frequência e ao peso de cada termo no documento, e quanto maior este número, mais relevante é a palavra.</p1><br>\n\nSegundo <a href = \"https://www.analyticsvidhya.com/blog/2020/02/quick-introduction-bag-of-words-bow-tf-idf/\">Analytics Vidhya</a>, o TF-IDF score é dado por: <br><br>\n\n$(TF - IDF)_{t,d} = TF_{t,d} * IDF_{t,d}$<br><br>\n<p1> onde \"t\" e \"d\" representam o termo analisado em um dado documento, respectivamente. Por definição, também temos a frequência do termo \"t\" no documento \"d\", dada por:</p1><br>\n* $TF_{t,d} = \\frac{\\textrm{nº de vezes que o termo \"t\" aparece no documento \"d\"}}{\\textrm{número total de termos no documento \"d\"}}$<br><br>\n\nE a importância do termo \"t\", definida como:<br>\n\n* $IDF_{t,d} = \\Big(\\frac{\\textrm{número de documentos}}{\\textrm{número de documentos que contém o termo \"t\"}}\\Big)$<br><br>"},{"metadata":{},"cell_type":"markdown","source":"Ainda segundo <a href = \"https://www.analyticsvidhya.com/blog/2020/02/quick-introduction-bag-of-words-bow-tf-idf/\">Analytics Vidhya</a>, apesar do modelo BoW ser mais simples no que se refere a interpretação, o modelo TD-IDF possui um desempenho maior quando comparado com o modelo Bag of Words em modelos de Machine Learning, uma vez que o TD-IDF traz informações sobre a importância das palavras e o modelo Bag of Words apenas traz informações sobre a ocorrência destas no documento. Neste notebook, por questões de praticidade usarei o modelo BoW"},{"metadata":{"trusted":true},"cell_type":"code","source":"#instanciando o vetor\nvectorizer = CountVectorizer(max_features = 300, min_df = 7, max_df = 0.8)\n\n#vetorizando\ncomentarios_vectorized = vectorizer.fit_transform(df['comentarios'])\n\nprint(comentarios_vectorized.shape)\n#print(comentarios_vectorized.A) #vizualização da matriz","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Treinamento</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#treinando o modelo\nmodelo = MultinomialNB() #instanciando o modelo de ML navie bayes-multinomial\nmodelo.fit(comentarios_vectorized, df['sentimento'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nfor comentario, classificacao in zip(df['comentarios'], modelo.predict(comentarios_vectorized)):\n    result_coment.append(comentario)\n    result_class.append(classificacao)\n    print(comentario + '  ' + classificacao)\n'''","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Predições</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"predicao = modelo.predict(comentarios_vectorized) #predicoes feitas pelo modelo\nproba = modelo.predict_proba(comentarios_vectorized) #probabilidade de cada classe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.DataFrame(columns = ['predicao', 'comentarios'])\nresult.predicao = predicao\nresult.comentarios = df['comentarios']\nresult['predicao'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Respostas</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}